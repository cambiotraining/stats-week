{
  "hash": "501be001112e0c8f9e01f0cb5950d3c9",
  "result": {
    "markdown": "---\ntitle: \"Fishcatch\"\nformat: html\n---\n\n::: {.cell}\n\n:::\n\n\nThe `data/fishcatch.csv` data set is from a study in Lake Längelmävesi, Finland. The data were originally collected in 1917 and now available through the [Journal of Statistics Education](https://jse.amstat.org/datasets/).\n\nThe data have been reformatted slightly for the purposes of this exercise.\n\nBriefly, the data set contains morphometric information on 7 different species of fish.\n\n## Step 1: Identify variables and research question\n\n### Load the data\n\nFirst, we load the data:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishcatch <- read_csv(\"data/fishcatch.csv\")\n```\n:::\n\n:::\n\n### Check the variable names and types\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishcatch\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 159 × 9\n     obs species      weight std_length fork_length total_length height_percent\n   <dbl> <chr>         <dbl>      <dbl>       <dbl>        <dbl>          <dbl>\n 1     1 common_bream    242       23.2        25.4         30             38.4\n 2     2 common_bream    290       24          26.3         31.2           40  \n 3     3 common_bream    340       23.9        26.5         31.1           39.8\n 4     4 common_bream    363       26.3        29           33.5           38  \n 5     5 common_bream    430       26.5        29           34             36.6\n 6     6 common_bream    450       26.8        29.7         34.7           39.2\n 7     7 common_bream    500       26.8        29.7         34.5           41.1\n 8     8 common_bream    390       27.6        30           35             36.2\n 9     9 common_bream    450       27.6        30           35.1           39.9\n10    10 common_bream    500       28.5        30.7         36.2           39.3\n# ℹ 149 more rows\n# ℹ 2 more variables: width_percent <dbl>, sex <chr>\n```\n:::\n:::\n\n:::\n\nWe can observe the following:\n\n* the data set contains 9 variables and 159 observations.\n* we have various continuous numerical variables (`weight`, `std_length`, `fork_length`, `total_length`)\n* we have percentage/ratio data (`height_percent`, `width_percent`)\n* we have categorical data (`species`, `sex`)\n* there is an observation number (`obs`, which is not informative for our analysis)\n* there are missing data, encoded as `NA`\n\n## Step 2: Describe the data\n\n### Data overview\n\nFirst, I like to get an idea of the type of observations I've got. It's really useful to have some counts on the different groups, so if there is anything strange/unexpected about the data then at least that's clear.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishcatch %>% \n  summary()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n      obs          species              weight         std_length   \n Min.   :  1.0   Length:159         Min.   :   0.0   Min.   : 7.50  \n 1st Qu.: 40.5   Class :character   1st Qu.: 120.0   1st Qu.:19.05  \n Median : 80.0   Mode  :character   Median : 272.5   Median :25.20  \n Mean   : 80.0                      Mean   : 398.7   Mean   :26.25  \n 3rd Qu.:119.5                      3rd Qu.: 650.0   3rd Qu.:32.70  \n Max.   :159.0                      Max.   :1650.0   Max.   :59.00  \n                                    NA's   :1                       \n  fork_length     total_length   height_percent  width_percent  \n Min.   : 8.40   Min.   : 8.80   Min.   :14.50   Min.   : 8.70  \n 1st Qu.:21.00   1st Qu.:23.15   1st Qu.:24.25   1st Qu.:13.40  \n Median :27.30   Median :29.40   Median :27.10   Median :14.60  \n Mean   :28.42   Mean   :31.23   Mean   :28.31   Mean   :14.12  \n 3rd Qu.:35.50   3rd Qu.:39.65   3rd Qu.:37.60   3rd Qu.:15.30  \n Max.   :63.40   Max.   :68.00   Max.   :44.50   Max.   :20.90  \n                                                                \n     sex           \n Length:159        \n Class :character  \n Mode  :character  \n                   \n                   \n                   \n                   \n```\n:::\n:::\n\n:::\n\nThings that stand out are:\n\n* there is a `weight` measurement of `0.0`. That can't be right and probably means \"missing\".\n* there are missing values in the data\n\nWe know that there are 7 different fish species measured. It's good to see how many observations there are in each group.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishcatch %>% \n  count(species)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 7 × 2\n  species            n\n  <chr>          <int>\n1 common_bream      35\n2 common_roach      20\n3 european_perch    56\n4 european_smelt    14\n5 ide                6\n6 northern_pike     17\n7 white_bream       11\n```\n:::\n:::\n\n\n:::\n\nThis illustrates the importance of this check. There is large variability in the number of observations. Were we to compare, for example, the average `total_length` between the different species then this average would be based on vastly different sample sizes.\n\nAnother categorical variable is `sex`, so let's have a look at that:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishcatch %>% \n  count(sex)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n  sex        n\n  <chr>  <int>\n1 female    55\n2 male      17\n3 <NA>      87\n```\n:::\n:::\n\n:::\n\nNot all observations have a sex indication; if we're to look at differences between females and males, particularly across species, then we need to consider this.\n\n### Plot the data\n\nPlotting the data can really help to get a sense of how the data are structured and distributed. It's also a great way of spotting any potential trends. The `fishcatch` data set is relatively small, particularly in terms of number of variables. This makes things a bit easier, since we don't have endless combinations of variables we can plot against each other.\n\nWhere to start though? A logical starting point would be to plot some of the morphometric measurements for each `species`. There are three length measurements and here I'm plotting `total_length`. Using a boxplot is helpful because it gives a visual indication on how the data are distributed:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(fishcatch,\n       aes(x = species, y = total_length)) +\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](case_fishcatch_files/figure-html/unnamed-chunk-7-1.png){width=672}\n:::\n:::\n\n\n:::\n\nI do very much like seeing the actual *data*, so I'm overlaying this as follows:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(fishcatch,\n       aes(x = species, y = total_length)) +\n  geom_boxplot() +\n  geom_jitter(alpha = 0.6, width = 0.1)\n```\n\n::: {.cell-output-display}\n![](case_fishcatch_files/figure-html/unnamed-chunk-8-1.png){width=672}\n:::\n:::\n\n:::\n\nRemember that the data also contains information on `sex` and it could very well be that some of these morphometric measurement are dependent on this. One way of visualising this is by creating subplots or facets. But since this variable contains many missing values, we need to remove these prior to plotting.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishcatch %>% \n  filter(!is.na(sex)) %>% \n  ggplot(aes(x = sex, y = total_length)) +\n  geom_boxplot() +\n  geom_jitter(alpha = 0.6, width = 0.1) +\n  facet_wrap(facets = vars(species))\n```\n\n::: {.cell-output-display}\n![](case_fishcatch_files/figure-html/unnamed-chunk-9-1.png){width=672}\n:::\n:::\n\n\n:::\n\nSo far, we have focussed on `total_length`, but there are more morphometric and biological measurements. Let's see if there is any relationship between them. For example, looking at `weight` against `total_length`.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(fishcatch,\n       aes(x = total_length,\n           y = weight,\n           colour = species)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](case_fishcatch_files/figure-html/unnamed-chunk-10-1.png){width=672}\n:::\n:::\n\n\n:::\n\nWe can see that there is quite some variability in `weight` across the species. Hardly surprising. But it can easily obscure patterns, because the data are across a wide range.\n\nLet's focus on the two species with the largest number of observations, which have a comparable body length: `common_bream` and `european_perch`.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishcatch %>% \n  filter(species %in% c(\"common_bream\", \"european_perch\")) %>% \n  ggplot(aes(x = total_length,\n             y = weight,\n             colour = species)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](case_fishcatch_files/figure-html/unnamed-chunk-11-1.png){width=672}\n:::\n:::\n\n:::\n\n### Dependencies and correlations\n\nThe morphometric measurements that were taken (`std_length`, `fork_length` and `total_length`) are not independent. A fish can't have a standard or fork length that is more than its total length, for example.\n\nThere is a high chance that there is some correlation between these variables. So let's check this. Note that you can only calculate correlations between numerical variables, so we need to remove any non-numerical variables first.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishcatch %>% \n  # unselect columns to exclude\n  select(-obs, -species, -sex) %>% \n  cor()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n               weight std_length fork_length total_length height_percent\nweight              1         NA          NA           NA             NA\nstd_length         NA 1.00000000  0.99951727   0.99203099     0.03710679\nfork_length        NA 0.99951727  1.00000000   0.99410263     0.05666101\ntotal_length       NA 0.99203099  0.99410263   1.00000000     0.13533814\nheight_percent     NA 0.03710679  0.05666101   0.13533814     1.00000000\nwidth_percent      NA 0.03006695  0.04247013   0.03569374     0.45265135\n               width_percent\nweight                    NA\nstd_length        0.03006695\nfork_length       0.04247013\ntotal_length      0.03569374\nheight_percent    0.45265135\nwidth_percent     1.00000000\n```\n:::\n:::\n\n\n:::\n\nThis returns a missing value for `weight` vs the other variables. If you recall from the summary statistics (and can spot in the graph above), there is at least one `weight` value of 0. Presumably that was used to encode a missing value, because a weight of 0 is of course not biologically possible.\n\nSo we need to remove this value before we calculate the correlations. To avoid issues going forward, we'll update the data set omitting the observations where `weight` is zero. In the end there is only one problematic observation! After removing it, we re-calculate the correlation coefficients.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishcatch %>% \n  filter(weight == 0)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 9\n    obs species      weight std_length fork_length total_length height_percent\n  <dbl> <chr>         <dbl>      <dbl>       <dbl>        <dbl>          <dbl>\n1    47 common_roach      0         19        20.5         22.8           28.4\n# ℹ 2 more variables: width_percent <dbl>, sex <chr>\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfishcatch <- fishcatch %>% \n  # keep rows where weight is not zero\n  filter(weight != 0)\n```\n:::\n\n\nRe-calculate the correlation coefficients:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishcatch %>% \n  select(-obs, -species, -sex) %>% \n  cor()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n                  weight std_length fork_length total_length height_percent\nweight         1.0000000 0.91645518  0.91936709   0.92453500     0.19437562\nstd_length     0.9164552 1.00000000  0.99951615   0.99211983     0.03514437\nfork_length    0.9193671 0.99951615  1.00000000   0.99418981     0.05475455\ntotal_length   0.9245350 0.99211983  0.99418981   1.00000000     0.13264248\nheight_percent 0.1943756 0.03514437  0.05475455   0.13264248     1.00000000\nwidth_percent  0.1355157 0.03178795  0.04425967   0.03773417     0.45606333\n               width_percent\nweight            0.13551573\nstd_length        0.03178795\nfork_length       0.04425967\ntotal_length      0.03773417\nheight_percent    0.45606333\nwidth_percent     1.00000000\n```\n:::\n:::\n\n:::\n\nFrom this correlation matrix we can deduce that there is a pretty high correlation between `weight` and the three length measurements (around $\\rho = 0.92$).\n\nImportantly, we can see that there is a very high correlation between the three length measurements themselves. This makes sense, since they are physically very similar. We'll see if this has any impact on our statistical analysis later on.\n\n### Consider whether there appear to be any significant effects of any of the variables\n\nIt looks like there could be a significant difference in `total_length` between the different species. If this is also dependent on the sex is less clear. There may be some small difference between females and males (e.g. in `white_bream`) but the number of observations are low and the difference is not clear-cut.\n\n### Consider your research question\n\nIn a real scientific setting you would of course not consider your research question after you have collected your data. So although we're considering it a bit late in the context of this analysis, the thought that goes into it remains the same. Looking back at the [Research questions](https://cambiotraining.github.io/stats-week/materials/research-questions.html) chapter, we need to ensure that the question is focused, researchable, relevant, feasible, original and complex.\n\nIn this case I'm going to exclude some of the data, to ensure the analysis remains clear. I'm going to focus on the potential relationship between `weight` and `total_length`, considering only the `common_bream` and `european_perch` species.\n\nMy question would be:\n\n> Can total length be used to predict the weight in common bream and European perch? If so, are there differences between the two species?\n\n## Step 3: Perform tests and or fit models\n\nBefore we start the analysis in earnest, we'll select just the required data.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubcatch <- fishcatch %>% \n  filter(species %in% c(\"common_bream\", \"european_perch\"))\n```\n:::\n\n:::\n\nWe're looking at a continuous predictor and a continuous response variable, so our best bet at this point is a linear model. Who'd have thunk? Let's visualise this first.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(subcatch,\n       aes(x = total_length, y = weight,\n           colour = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](case_fishcatch_files/figure-html/unnamed-chunk-17-1.png){width=672}\n:::\n:::\n\n:::\n\nHmmm, that looks alright for the `common_bream` but pretty awful for the `european_perch` data. The latter has a tiddler weighing 5.9 grams, with a length of 8.8 cm. Let's not judge size, but it is annoying.\n\nThat said, the `european_perch` measurements have quite some measured values at the lower scale, whereas the `common_bream` does not. One explanation could be that there were juvenile European perches in the lake, but in the absence of further information (which we're unlikely to get from 1917 researchers), all we can do is guess.\n\n### Select a test appropriate to the data that you have\n\nThe linear model we've visualised above takes into account the `total_length` and `weight:total_length` interaction. Note that it does not consider the `std_length` and `fork_length` variables. Whether this is necessary, we don't really know. Nor do we know if the assumptions of a linear model are met. More on that later.\n\nLet's look and see if our model makes any sense, statistically speaking.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_full <- lm(weight ~ total_length * species,\n              data = subcatch)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(lm_full)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: weight\n                     Df  Sum Sq Mean Sq  F value    Pr(>F)    \ntotal_length          1 8511522 8511522 1167.253 < 2.2e-16 ***\nspecies               1   94562   94562   12.968 0.0005293 ***\ntotal_length:species  1   78572   78572   10.775 0.0014879 ** \nResiduals            86  627106    7292                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n:::\n\nThe `total_length:species` interaction is statistically significant, so we can't ignore it. It means that the effect of `weight` on `total_length` is dependent on `species`.\n\n::: {.callout-note collapse=\"true\"}\n\nHere the research question specifically stated the relationship between `total_length` and `weight`. What if we wanted to take into account the `std_length` and `fork_length` variables as well? The linear model would become rather long if we accounted for *all* the possible interactions. We could however define a model that at least took these two additional variables into account as main effects:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm(weight ~ std_length + fork_length + total_length * species,\n              data = subcatch)\n```\n:::\n\n:::\n\nWe could then use **backwards stepwise elimination** to arrive at the most parsimonious model.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nstep(lm(weight ~ std_length + fork_length + total_length * species,\n              data = subcatch))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nStart:  AIC=807.32\nweight ~ std_length + fork_length + total_length * species\n\n                       Df Sum of Sq    RSS    AIC\n- fork_length           1         2 619538 805.32\n- std_length            1      4033 623569 805.91\n<none>                              619536 807.32\n- total_length:species  1     58152 677688 813.40\n\nStep:  AIC=805.32\nweight ~ std_length + total_length + species + total_length:species\n\n                       Df Sum of Sq    RSS    AIC\n- std_length            1      7568 627106 804.42\n<none>                              619538 805.32\n- total_length:species  1     59292 678830 811.55\n\nStep:  AIC=804.42\nweight ~ total_length + species + total_length:species\n\n                       Df Sum of Sq    RSS    AIC\n<none>                              627106 804.42\n- total_length:species  1     78572 705678 813.04\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = weight ~ total_length + species + total_length:species, \n    data = subcatch)\n\nCoefficients:\n                       (Intercept)                        total_length  \n                          -1187.12                               47.23  \n             specieseuropean_perch  total_length:specieseuropean_perch  \n                            534.33                              -12.23  \n```\n:::\n:::\n\n:::\n\nUsing this approach we arrive at a final model that takes into account the `species` term as well as the `total_length:species` interaction. This makes sense from our previous exploration: the three length terms are highly correlated and `total_length` incorporates the `std_length` and `fork_length` values. As such, these two variables do not contribute markedly to explaining the data, since most of that is already done by `total_length`.\n:::\n\n### Check assumptions of tests/models\n\nLet's check the assumptions of our `weight ~ total_length * species` model.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresid_panel(lm_full,\n            plots = c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n            smoother = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](case_fishcatch_files/figure-html/unnamed-chunk-22-1.png){width=672}\n:::\n:::\n\n\n:::\n\nOh dear. The diagnostic plots do not look very good. To be honest, it's not a huge surprise, given what we saw before in the `european_perch` data.\n\nProblems:\n\n* our residuals are not very homogenous\n* the Q-Q plot doesn't look great with deviation away from the diagonal\n* the location-scale plot suggest that there are problems with equality of variance\n* there is one value with a Cook's d value of > 0.5, so that is a data point I'd check for unduly influence\n\n### Reassess model\n\nGiven the issues with the data, we can't just fit a linear model. We could see if we can transform the data in such a way that we can fit a linear model.\n\nUpside: we can use a linear model. Downside: interpreting the model becomes a bit trickier.\n\nOne option would be to log-transform the `weight` variable. The best way to show why this is useful is to illustrate it:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(subcatch,\n       aes(x = total_length, y = log(weight),\n           colour = species)) +\n  geom_point() +\n  geom_smooth(method = \"lm\", se = FALSE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](case_fishcatch_files/figure-html/unnamed-chunk-23-1.png){width=672}\n:::\n:::\n\n\n:::\n\nOur tiddler data point (most left) has a reduced influence on the line of best fit for the `european_perch`. The lower-weight values are also much closer to the line.\n\nAs such, we could redefine the model as follows:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_full_log <- lm(log(weight) ~ total_length * species,\n              data = subcatch)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(lm_full_log)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: log(weight)\n                     Df Sum Sq Mean Sq  F value    Pr(>F)    \ntotal_length          1 83.188  83.188 1743.544 < 2.2e-16 ***\nspecies               1  0.016   0.016    0.335  0.564268    \ntotal_length:species  1  0.478   0.478   10.008  0.002154 ** \nResiduals            86  4.103   0.048                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n:::\n\nThe `total_length:species` interaction remains statistically significant, so we still can't ignore it. But instead of using `weight` as the response variable, we are now using the `log(weight)` value as a response.\n\nLet's re-evaluate the assumptions to see if they have improved.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresid_panel(lm_full_log,\n            plots = c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n            smoother = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](case_fishcatch_files/figure-html/unnamed-chunk-26-1.png){width=672}\n:::\n:::\n\n\n:::\n\n#### Influential points\n\nThat one data point really seems to throw a spanner in the works. So let's look at that a bit closer.\n\nWe can extract the Cook's d values and look for the highest one.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_full_log %>%\n  augment() %>%\n  arrange(desc(.cooksd))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 90 × 9\n   `log(weight)` total_length species       .fitted .resid   .hat .sigma .cooksd\n           <dbl>        <dbl> <chr>           <dbl>  <dbl>  <dbl>  <dbl>   <dbl>\n 1          1.77          8.8 european_per…    3.15 -1.37  0.104   0.153  1.28  \n 2          6.91         46.6 european_per…    7.35 -0.447 0.0759  0.214  0.0931\n 3          6.91         46   european_per…    7.29 -0.380 0.0719  0.215  0.0632\n 4          5.49         30   common_bream     5.70 -0.212 0.149   0.218  0.0487\n 5          3.47         14.7 european_per…    3.80 -0.339 0.0621  0.216  0.0426\n 6          6.91         45.2 european_per…    7.20 -0.291 0.0668  0.217  0.0341\n 7          6.86         46.5 common_bream     7.04 -0.183 0.142   0.219  0.0338\n 8          6.73         37.3 european_per…    6.32  0.414 0.0298  0.215  0.0284\n 9          6.48         41.4 european_per…    6.78 -0.299 0.0459  0.217  0.0236\n10          3.69         16   european_per…    3.95 -0.261 0.0547  0.218  0.0218\n# ℹ 80 more rows\n# ℹ 1 more variable: .std.resid <dbl>\n```\n:::\n:::\n\n:::\n\nPerhaps unsurprisingly, this value comes from our tiddler, `obs 104`.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfishcatch %>% arrange(weight)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 157 × 9\n     obs species       weight std_length fork_length total_length height_percent\n   <dbl> <chr>          <dbl>      <dbl>       <dbl>        <dbl>          <dbl>\n 1   104 european_per…    5.9        7.5         8.4          8.8           24  \n 2    73 european_sme…    6.7        9.3         9.8         10.8           16.1\n 3    75 european_sme…    7         10.1        10.6         11.6           14.9\n 4    74 european_sme…    7.5       10          10.5         11.6           17  \n 5    78 european_sme…    8.7       10.8        11.3         12.6           15.7\n 6    76 european_sme…    9.7       10.4        11           12             18.3\n 7    77 european_sme…    9.8       10.7        11.2         12.4           16.8\n 8    81 european_sme…    9.8       11.4        12           13.2           16.7\n 9    80 european_sme…    9.9       11.3        11.8         13.1           16.9\n10    79 european_sme…   10         11.3        11.8         13.1           16.9\n# ℹ 147 more rows\n# ℹ 2 more variables: width_percent <dbl>, sex <chr>\n```\n:::\n:::\n\n:::\n\nWe can remove this data point and re-run the analysis. However, you have to be careful doing this and generally be able to justify removing \"outliers\". Just because a data point does not fit with your proposed model, that does not mean you can just remove it. If we'd have access to the publication / researchers then we would ask them if there was anything unusual that they remembered about this particular sample.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubcatch_outlier <- subcatch %>% \n  filter(obs != 104)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_outlier_log <- lm(log(weight) ~ total_length * species,\n                     data = subcatch_outlier)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(lm_outlier_log)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: log(weight)\n                     Df Sum Sq Mean Sq  F value    Pr(>F)    \ntotal_length          1 69.044  69.044 2938.042 < 2.2e-16 ***\nspecies               1  0.001   0.001    0.039 0.8440051    \ntotal_length:species  1  0.294   0.294   12.509 0.0006587 ***\nResiduals            85  1.998   0.024                       \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nresid_panel(lm_outlier_log,\n            plots = c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n            smoother = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](case_fishcatch_files/figure-html/unnamed-chunk-32-1.png){width=672}\n:::\n:::\n\n\n:::\n\n### Cube root to the rescue?\n\nThe assumptions above are still pretty rubbish. So clearly the log transformation (with our without the influential point) is not really the way to go.\n\nWe could try a different transformation, where we take the cube root of `weight`. I know what you're thinking at this point - how can make these decisions and what is the impact on the interpretation?\n\nI admit that things are a bit fuzzy at this point. From our earlier look at the data we already had reservations about the linearity of the relationship `weight ~ total_length`. We tried to fix this with transforming the data, which didn't really work. Below you'll see how the relationship `weight^(1/3) ~ total_length` has much better diagnostic plots etc. But the troubling thing is:\n\n> Every one unit increase in your predictor variable, what does this mean in terms of the response variable?\n\nWhat does a unit increase affecting $\\sqrt[3]{weight}$ mean? We'd be much better off performing a non-linear regression analysis instead.\n\nFor now, let's see what all of this looks like. For ease, we'll create a new variable that contains the values of $\\sqrt[3]{weight}$.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsubcatch <- subcatch %>%\n  mutate(weight_cuberoot = weight ^ (1/3))\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsubcatch %>% \n  ggplot(aes(x = total_length,\n             y = weight_cuberoot,\n             colour = species)) +\n  geom_point()\n```\n\n::: {.cell-output-display}\n![](case_fishcatch_files/figure-html/unnamed-chunk-34-1.png){width=672}\n:::\n:::\n\n:::\n\nNext, we can create a linear model based on this response variable and check the assumptions.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_cuberoot <- lm(weight_cuberoot ~ total_length * species,\n                  data = subcatch)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(lm_cuberoot)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: weight_cuberoot\n                     Df Sum Sq Mean Sq   F value  Pr(>F)    \ntotal_length          1 375.19  375.19 5160.7466 < 2e-16 ***\nspecies               1   0.41    0.41    5.6466 0.01971 *  \ntotal_length:species  1   0.05    0.05    0.6667 0.41646    \nResiduals            86   6.25    0.07                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\n:::\n\nHere the interaction is no longer significant, because the response variable is on a different scale. Part of the issue with simply transforming the data is that it also transforms the residuals. This clearly has an effect here.\n\nBut, let's remove the interaction and look again:\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlm_cuberoot_red <- lm(weight_cuberoot ~ total_length + species,\n                      data = subcatch)\n```\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nanova(lm_cuberoot_red)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nAnalysis of Variance Table\n\nResponse: weight_cuberoot\n             Df Sum Sq Mean Sq   F value  Pr(>F)    \ntotal_length  1 375.19  375.19 5180.5931 < 2e-16 ***\nspecies       1   0.41    0.41    5.6683 0.01946 *  \nResiduals    87   6.30    0.07                      \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n:::\n\nThe `total_length` and `species` main effects remain statistically significant, so let's look at the assumptions.\n\n::: {.panel-tabset group=\"language\"}\n## R\n\n\n::: {.cell}\n\n```{.r .cell-code}\nresid_panel(lm_cuberoot_red,\n            plots = c(\"resid\", \"qq\", \"ls\", \"cookd\"),\n            smoother = TRUE)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n`geom_smooth()` using formula = 'y ~ x'\n`geom_smooth()` using formula = 'y ~ x'\n```\n:::\n\n::: {.cell-output-display}\n![](case_fishcatch_files/figure-html/unnamed-chunk-39-1.png){width=672}\n:::\n:::\n\n\n### Assess results of model fit\n",
    "supporting": [
      "case_fishcatch_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}